{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = dict{1:'Benefits_Cost_Sharing_PUF.csv'\\\n",
    "            ,2:'Business_Rules_PUF.csv'\\\n",
    "            ,3:'Network_PUF.csv'\\\n",
    "            ,4:'Plan_Attributes_PUF_2014_2015-03-09.csv'\\\n",
    "            ,5:'Rate_PUF.csv'\n",
    "            ,6: 'Service_Area_PUF.csv'\\\n",
    "            }\n",
    "def file_selector():\n",
    "    number_files =input(\"'A'll, 'Y'ear or 'F'iles or 'S'ingle? ->\")\n",
    "    if number_files=='F' or number_files == 'A':\n",
    "        year =input('Which year?->')\n",
    "    if number_files=='S':\n",
    "        file = input(f\"Which file? (choose #)\\n {files}\")\n",
    "        df = pd.read_csv(f'data/{year}/{file}',low_memory=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#fileload_counter determines whether to send a welcome message when file_chooser() is called.\n",
    "fileloader_counter = 0\n",
    "\n",
    "\n",
    "#def make_attributes(year=2014,file='Benefits_Cost_Sharing_PUF.csv'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "year=2014\n",
    "file='Benefits_Cost_Sharing_PUF.csv'\n",
    "cost=pd.read_csv(f'data/{year}/{file}',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "'''\n",
    "for header in headers:\n",
    "    attr=uniquedict[header]   \n",
    "    np.sort(attr) \n",
    "    print(header)\n",
    "    \n",
    "    pauser=input('COPY AND PASTE!')\n",
    "'''\n",
    "\n",
    "attr=uniquedict['SourceName']   \n",
    "np.sort(attr) \n",
    "\n",
    "\n",
    "\n",
    "cost=pd.read_csv(f'data/{year}/Benefits_Cost_Sharing_PUF.csv',low_memory=False)\n",
    "headers=list(cost.columns)\n",
    "uniques=[]\n",
    "for header in headers:\n",
    "    col=cost[header]\n",
    "    uniques.append(col.unique())\n",
    "\n",
    "uniquedict=dict(zip(headers,uniques))\n",
    "'''\n",
    "for header in headers:\n",
    "    attr=uniquedict[header]   \n",
    "    np.sort(attr) \n",
    "    print(header)\n",
    "    \n",
    "    pauser=input('COPY AND PASTE!')\n",
    "'''\n",
    "\n",
    "attr=uniquedict['SourceName']   \n",
    "np.sort(attr) \n",
    "'''\n",
    "def file_chooser(num_files= 1, year=2014, file ='data/Benefits_Cost_Sharing_PUF.csv'):\n",
    "     This function allows the user to select the years and files to use\n",
    "\n",
    "    vars:\n",
    "\n",
    "\n",
    "\n",
    "    fileloader_counter = 0 displays a welcome. Otherwise it goes to the selection portion.\n",
    "    year = the user entered year\n",
    "    file_list = the available files\n",
    "    file = the user chosen file\n",
    "\n",
    "\n",
    "    \n",
    "    if fileloader_counter == 0:\n",
    "        print('Welcome to the CMS Marketplace dataset. The first step is to load\\n \\\n",
    "            files. There are 3 default years and 6 default files')\n",
    "    fileloader_counter +=1\n",
    "    while year != 'q':\n",
    "        year = input(\"The default years are 2014, 2015, and 2016. Please enter \\n\\\n",
    "            the year you wish to use as an integer or 'q' to quit->\")\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.py\n",
    "#cost2014=pd.read_csv('data/2014/Benefits_Cost_Sharing_PUF.csv',low_memory=False)\n",
    "#cost2015=pd.read_csv('data/2015/Benefits_Cost_Sharing_PUF.csv',low_memory=False)\n",
    "##cost2016=pd.read_csv('data/2016/Benefits_Cost_Sharing_PUF_2015-12-08.csv',low_memory=False)\n",
    "#rules2014=pd.read_csv('data/2014/Business_Rules_PUF.csv',low_memory=False)\n",
    "#rules2015=pd.read_csv('data/2015/Business_Rules_PUF_Reformat.csv',low_memory=False)\n",
    "#rules2016=pd.read_csv('data/2016/Business_Rules_PUF_2015-12-08.csv',low_memory=False)\n",
    "#network2014=pd.read_csv('data/2014/Network_PUF.csv',low_memory=False)\n",
    "#network2015=pd.read_csv('data/2015/Network_PUF.csv',low_memory=False)\n",
    "#network2016=pd.read_csv('data/2016/Network_PUF.csv',low_memory=False)\n",
    "#attr2014=pd.read_csv('data/2014/Plan_Attributes_PUF_2014_2015-03-09.csv',low_memory=False)\n",
    "#attr2015=pd.read_csv('data/2015/Plan_Attributes_PUF.csv',low_memory=False)\n",
    "#attr2016=pd.read_csv('data/2016/Plan_Attributes_PUF.csv',low_memory=False)\n",
    "#rate2014=pd.read_csv('data/2014/Rate_PUF.csv',low_memory=False)\n",
    "#rate2015=pd.read_csv('data/2015/Rate_PUF.csv',low_memory=False)\n",
    "#rate2016=pd.read_csv('data/2016/Rate_PUF.csv',low_memory=False)\n",
    "#area2014=pd.read_csv('data/2014/Service_Area_PUF.csv',low_memory=False)\n",
    "#area2015=pd.read_csv('data/2015/Service_Area_PUF.csv',low_memory=False)\n",
    "#area2016=pd.read_csv('data/2016/ServiceArea_PUF_2015-12-08.csv',low_memory=False)\n",
    "#cross1415=pd.read_csv('data/2015/Plan_Crosswalk_PUF_2014-12-22.csv',low_memory=False)\n",
    "#machine16=pd.read_excel('data/2015/Machine_Readable_PUF_2015-12-21.xlsx',low_memory=False)#\n",
    "\n",
    "\n",
    "'''\n",
    "def importdf(sample_size):\n",
    "\n",
    "\n",
    "    list_cost = []\n",
    "    list_rules = []\n",
    "    list_network = []\n",
    "    list_attributes = []\n",
    "    list_service_area = []\n",
    "    list_rate = []\n",
    "    list_others= []\n",
    "\n",
    "\n",
    "    for filename in all_files:ignore_index=True\n",
    "        df = pd.read_csv(filename, index_col=None, header=0, low_memory=False)\n",
    "        \n",
    "        \n",
    "        if filename[6]=='u':\n",
    "            list_rules.append(df)\n",
    "        elif filename[5]=='B':\n",
    "            list_cost.append(df)\n",
    "        elif filename[5]=='N':\n",
    "            list_network.append(df)\n",
    "        elif filename[5]=='P':\n",
    "            list_attributes.append(df)\n",
    "        elif filename[5]=='S':\n",
    "            list_service_area.append(df)\n",
    "        elif filename[5]=='R':\n",
    "            list_rate.append(df)\n",
    "        else:\n",
    "            list_others.append(df)\n",
    "\n",
    "dfcost = pd.concat(list_cost, sort=False)\n",
    "\n",
    "    dfrules = pd.concat(list_rules, axis=0, ignore_index=True)\n",
    "    dfnetwork= pd.concat(list_network, axis=0, ignore_index=True)\n",
    "    dfattribiutes = pd.concat(list_attributes, axis=0, ignore_index=True)\n",
    "    dfservice_area = pd.concat(list_service_area, axis=0, ignore_index=True)\n",
    "    dfrate = pd.concat(list_rate, axis=0, ignore_index=True)\n",
    "\n",
    "    #Commented out to stop error function. Can be uncommented if needed.\n",
    "    # dfother = pd.concat(list_other, axis=0, ignore_index=True)\\\n",
    "''' \n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "workbook = xlsxwriter.Workbook('data/attribute_files/cost2014_attr.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for key in d.keys():\n",
    "    row += 1\n",
    "    worksheet.write(row, col, key)\n",
    "    for item in d[key]:\n",
    "        worksheet.write(row, col + 1, item)\n",
    "        row += 1\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#files = ['data/2014/Service_Area_PUF.csv','data/2015/Service_Area_PUF.csv','data/2016/Service_Area_PUF.csv']\n",
    "\n",
    "\n",
    "#result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
    "\n",
    "'''\n",
    "for i in range(3):\n",
    "   .....:     data = pd.DataFrame(np.random.randn(10, 4))\n",
    "   .....:     data.to_csv('file_{}.csv'.format(i))\n",
    "\n",
    "\n",
    "#cost2014=pd.read_csv('data/2014/Benefits_Cost_Sharing_PUF.csv',chunksize=chunksize)\n",
    "#cost2015=pd.read_csv('data/2015/Benefits_Cost_Sharing_PUF.csv',low_memory=False)\n",
    "#cost2016=pd.read_csv('data/2016/Benefits_Cost_Sharing_PUF_2015-12-08.csv',low_memory=False)\n",
    "costall1=pd.concat([cost2014, 2015], axis=1)\n",
    "del cost2014\n",
    "del cost2015\n",
    "\n",
    "chunksize = 10000\n",
    "chunks = []\n",
    "for chunk in pd.read_csv('data/2016/Benefits_Cost_Sharing_PUF_2015-12-08.csv', chunksize=chunksize):\n",
    "    # Do stuff...\n",
    "    costall = pd.concat([costall,chunks] axis=1)\n",
    "\n",
    "files = [cost2014,cost2015,cost2016]\n",
    "original = pandas.DataFrame({\n",
    "    'Age':[10, 12, 13], \n",
    "    'Gender':['M','F','F']})\n",
    "\n",
    "# Note this column has 4 rows of values:\n",
    "additional = pandas.DataFrame({\n",
    "    'Name': ['Nate A', 'Jessie A', 'Daniel H', 'John D']\n",
    "})\n",
    "\n",
    "new = pandas.concat([original, additional], axis=1) \n",
    "# Identical:\n",
    "# new = pandas.concat([original, additional], ignore_index=False, axis=1) \n",
    "\n",
    "print(new.head())\n",
    "\n",
    "#          Age        Gender        Name\n",
    "#0          10             M      Nate A\n",
    "#1          12             F    Jessie A\n",
    "#2          13             F    Daniel H\n",
    "#3         NaN           NaN      John D\n",
    "\n",
    "df=cost2014.copy(deep=True)\n",
    "#dfprop = df.info()\n",
    "headers=list(df.columns)\n",
    "uniques=[]\n",
    "for header in headers:\n",
    "    col=df[header]\n",
    "    uniques.append(col.unique())\n",
    "\n",
    "uniquedict=dict(zip(headers,uniques))\n",
    "import xlsxwriter\n",
    "\n",
    "workbook = xlsxwriter.Workbook('data/attribute_files/cost2014_attr.xlsx',{'nan_inf_to_errors': True,'constant_memory': True} )\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "order=sorted(uniquedict.keys())\n",
    "\n",
    "for key in order:\n",
    "    row += 1\n",
    "    worksheet.write(row, col,     key)\n",
    "    i =1\n",
    "    for item in uniquedict[key]:\n",
    "        worksheet.write(row, col + i, item)\n",
    "        i += 1\n",
    "\n",
    "workbook.close()\n",
    "'''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cost_all=pd.read_csv('data/merged/cost_all.csv',low_memory=False)\n",
    "rules_all=.pd.read_csv('data/merged/cost_all.csv',low_memory=False)\n",
    "network_al=to_csv('data/merged/cost_all.csv',low_memory=False)\n",
    "attr_all=.to_csv('data/merged/attr_all.csv')\n",
    "rate_all=.to_csv('data/merged/rate_all.csv')\n",
    "area_all=.to_csv('data/merged/area_all.csv')\n",
    "cross_all=.to_csv('data/merged/cross_all.csv')\n",
    "machine1.to_csv('data/merged/machine16.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "filename = Path(\"source_data/text_files/raw_data.txt\")\n",
    "\n",
    "print(filename.name)\n",
    "# prints \"raw_data.txt\"\n",
    "\n",
    "print(filename.suffix)\n",
    "# prints \"txt\"\n",
    "\n",
    "print(filename.stem)\n",
    "# prints \"raw_data\"\n",
    "\n",
    "if not filename.exists():\n",
    "    print(\"Oops, file doesn't exist!\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_folder = Path(\"source_data/text_files/\")\n",
    "\n",
    "file_to_open = data_folder / \"raw_data.txt\"\n",
    "\n",
    "print(file_to_open.read_text())\n",
    "\n",
    " Path('.').exists()\n",
    "True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
